# OVERVIEW
This project:
- builds a machine learning (ML) model that will classify documents as
important or not important.
- provides the ability to generate a probability score from 0 to 100
to the documents, where the score is the prediction score.


## DATA
This dataset was collected and prepared by the 
[CALO Project](A Cognitive Assistant that Learns and Organizes).
It contains data from about 150 users, organized into forlders.
The corpus contains approximately 500k emails generated by
employees of the Enron Corporation. It was obtained by the Federal Energy
Regulatory Commission during its investigation of Enron's collapse.

This is the dataset from 2015-05-07, as published at 
[CMU webiste](https://www.cs.cmu.edu/~./enron/).


## ARCHITECTURE
This simple architecture can be modified to expand into a
cloud infrastructure and/or more automated and streamlines process.
<to insert technical architecture diagram>

Each python script needs to be executed to do the following tasks:
- **Data load**: the zip file is unzipped and loaded into a dataframe.
This is a time-intensive process. The resulting dataframe is saved as
a `.pkl` file in order to process the dataframe downstream. The resulting
dataframe has the following three columns:
| FilePath | FileID | RawContents |
| --- | --- | --- |
| \filename | id1 | contents | 
| \filename | id2 | contents | 
| \filename | id3 | contents | 

- **Data processing**: For the sake of the project, the 10\% of the
data is assigned two labels - 1 and 0 - 1 implying that the file is
relevant and important, 0 otherwise.
The resulting dataframe is -
| FileID | Label |
| --- | --- |
| id1 | 1 |
| id2 | 1 |
| id3 |  |
| id4 |  |
...
| id200 | 0 |
...
| id1023 | 1 |
| id1025 | 0 |
| ... | ... |

The null means that there are no labels for these documents.

